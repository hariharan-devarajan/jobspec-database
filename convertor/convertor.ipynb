{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import traceback\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torch.utils.data import Dataset, RandomSampler, DataLoader\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/p/vast1/haridev/jobspec-database/data',\n",
       " '/p/vast1/haridev/jobspec-database/converted_data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(project_dir, \"data\")\n",
    "output_dir = os.path.join(project_dir, \"converted_data\")\n",
    "data_dir, output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a008b1f567204c05a7eb7001affb3789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collected_size = 0\n",
    "collected_counter = 0\n",
    "max_size = 1024*1024*32\n",
    "h5_fname = f\"{output_dir}/job_scripts_{collected_counter}.h5\"\n",
    "h5_file = None\n",
    "try:\n",
    "    h5_file = h5py.File(h5_fname,'w')\n",
    "    files = glob.iglob(f\"{data_dir}/**/*\", recursive=True)\n",
    "    for filename in tqdm(files):\n",
    "        path = os.path.abspath(filename)\n",
    "        filename = os.path.relpath(path, data_dir)\n",
    "        dirname = os.path.dirname(filename)\n",
    "        filename = os.path.basename(filename)\n",
    "        if os.path.isfile(path):\n",
    "            # print(filename, dirname)\n",
    "            with open(path, \"rb\") as in_file:\n",
    "                data = in_file.read()\n",
    "                size = len(data)\n",
    "            if size > 0:\n",
    "                if collected_size + size > max_size:\n",
    "                    # print(f\"Collected {collected_size} bytes into {h5_fname}\")\n",
    "                    h5_file.close()\n",
    "                    collected_counter += 1\n",
    "                    h5_fname = f\"{output_dir}/job_scripts_{collected_counter}.h5\"\n",
    "                    collected_size = 0\n",
    "                    h5_file = h5py.File(h5_fname,'w')\n",
    "                collected_size += size\n",
    "                if dirname not in h5_file.keys():\n",
    "                    h5_group = h5_file.create_group(dirname)\n",
    "                else:\n",
    "                    h5_group = h5_file[dirname]\n",
    "                ds = h5_group.create_dataset(filename, shape=1, dtype=h5py.string_dtype(length=size), chunks=tuple([1]))\n",
    "                ds[:] = data\n",
    "    h5_file.close()\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    print(traceback.format_exc())\n",
    "    if h5_file:\n",
    "        h5_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/p/vast1/haridev/jobspec-database/converted_data/job_scripts_0.h5',\n",
       "  '/002311-A/csci-467-project/bert_baseline.job'),\n",
       " ('/p/vast1/haridev/jobspec-database/converted_data/job_scripts_0.h5',\n",
       "  '/002311-A/csci-467-project/jobspec-cfg/bert_baseline_lime_args.py'),\n",
       " ('/p/vast1/haridev/jobspec-database/converted_data/job_scripts_0.h5',\n",
       "  '/00dylan00/siganturizer3D_models/scripts/slurm.bottom.all.limited.sh'),\n",
       " ('/p/vast1/haridev/jobspec-database/converted_data/job_scripts_0.h5',\n",
       "  '/00dylan00/siganturizer3D_models/scripts/slurm.bottom.all.sh'),\n",
       " ('/p/vast1/haridev/jobspec-database/converted_data/job_scripts_0.h5',\n",
       "  '/00dylan00/siganturizer3D_models/scripts/slurm.top.all.sh'),\n",
       " ('/p/vast1/haridev/jobspec-database/converted_data/job_scripts_0.h5',\n",
       "  '/01-vyom/melanoma-classification/src/BYOL/resnet.sh'),\n",
       " ('/p/vast1/haridev/jobspec-database/converted_data/job_scripts_0.h5',\n",
       "  '/02zx/02zx.github.io/tutorial/free%20energy/water/Thermodynamics%20Integration/run.sh'),\n",
       " ('/p/vast1/haridev/jobspec-database/converted_data/job_scripts_0.h5',\n",
       "  '/02zx/02zx.github.io/tutorial/free%20energy/water/hamitonian%20integration/225K/run.sh'),\n",
       " ('/p/vast1/haridev/jobspec-database/converted_data/job_scripts_0.h5',\n",
       "  '/100shpaik/RKStest-code/codes/bash.sh'),\n",
       " ('/p/vast1/haridev/jobspec-database/converted_data/job_scripts_0.h5',\n",
       "  '/1054/Crab.Toolkit.JWST/bin/go-qsub-jwst-imaging-jobarray-group.bash')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "from collections import Iterable\n",
    "def flatten(coll):\n",
    "    for i in coll:\n",
    "            if isinstance(i, Iterable) and not isinstance(i, str):\n",
    "                for subc in flatten(i):\n",
    "                    yield subc\n",
    "            else:\n",
    "                yield i\n",
    "def get_recursive_path(obj, current):\n",
    "    invert_op = getattr(obj, \"keys\", None)\n",
    "    # print(current, invert_op)\n",
    "    if invert_op is not None:\n",
    "        keys = obj.keys()\n",
    "        if len(keys) > 0:\n",
    "            values = []\n",
    "            for key in keys:\n",
    "                new = f\"{current}/{key}\"\n",
    "                values.append(get_recursive_path(obj[key], new))\n",
    "            return flatten(values)\n",
    "    else:\n",
    "        return current\n",
    "\n",
    "files = glob.iglob(f\"{output_dir}/*.h5\", recursive=True)\n",
    "job_spec_idx = []\n",
    "for file in files:\n",
    "    h5_file = h5py.File(file,'r')\n",
    "    for value in get_recursive_path(h5_file, \"\"):\n",
    "        job_spec_idx.append((file, value))\n",
    "job_spec_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(fname, dataset):\n",
    "    h5_file = h5py.File(fname,'r')\n",
    "    data = h5_file[dataset][0]\n",
    "    h5_file.close()\n",
    "    return data\n",
    "    \n",
    "class JobSpecDataset(Dataset):    \n",
    "    def __init__(self, sample_map):\n",
    "        self.sample_map = sample_map\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample_map)\n",
    "\n",
    "    def __getitem__(self, image_idx):\n",
    "        fname, dataset = self.sample_map[image_idx]\n",
    "        data = get_item(fname, dataset)\n",
    "        # print(data)\n",
    "        return (image_idx, np.array([data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = JobSpecDataset(job_spec_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "if num_workers==0:\n",
    "    kwargs={}\n",
    "else:\n",
    "    kwargs={'prefetch_factor': 16} # Can store 16 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "seed = int(torch.empty((), dtype=torch.int64).random_().item())\n",
    "# generator needs to load up torch seed.\n",
    "torch_generator = torch.Generator()\n",
    "torch_generator.manual_seed(seed)\n",
    "# Pass generator to sampler\n",
    "sampler = RandomSampler(dataset, generator=torch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = DataLoader(dataset, batch_size=None, \n",
    "                              sampler=sampler,\n",
    "                              num_workers=num_workers,\n",
    "                              **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [38715, array([b'#PBS -N rrnabl_mn_0_ans-1000_a\\n#PBS -l walltime=5:00:00\\n#Name of job\\n#Dep name , project name\\n#PBS -P cse\\n##PBS -P darpa.ml.cse\\n##PBS -P parags.p2.54\\n##PBS -q high \\n#PBS -j oe\\n#PBS -m bea\\n### Specify email address to use for notification.\\n#PBS -M $USER@iitd.ac.in\\n#PBS -l select=3:ngpus=2:ncpus=3:centos=skylake\\n##PBS -l select=3:ngpus=2:ncpus=2:centos=skylake\\n## SPECIFY JOB NOW\\n\\nCURTIME=$(date +%Y%m%d%H%M%S)\\n##module load apps/pythonpackages/3.6.0/pytorch/0.4.1/gpu\\n##module load apps/anaconda3/4.6.9\\n##module load apps/anaconda/3\\n##module load apps/pytorch/1.5.0/gpu/anaconda3\\n## Change to dir from where script was launched\\n\\n\\n\\n\\ncount=0\\n\\n\\ndeclare -a var\\ninit_count=$count \\nwhile read p; do\\n      echo $p\\n      #script=\"source /usr/share/Modules/3.2.10/init/bash && CUDA_VISIBLE_DEVICES=0 nohup /home/yatin/phd/misc-scripts/hpcv2/hpc_jobs/rrn_equal_abl_rep/exp_${count}.sh > /home/yatin/phd/misc-scripts/hpcv2/hpc_jobs/rrn_equal_abl_rep/LOG_${count} 2>&1 &\"\\n      script=\"CUDA_VISIBLE_DEVICES=0 nohup /home/yatin/phd/misc-scripts/hpcv2/hpc_jobs/rrn_equal_abl_rep/exp_${count}.sh > /home/yatin/phd/misc-scripts/hpcv2/hpc_jobs/rrn_equal_abl_rep/LOG_${count} 2>&1 &\"\\n      echo $script\\n      ssh -o StrictHostKeyChecking=no -n -f ${USER}@$p $script\\n      var[`expr $count - $init_count`]=/home/yatin/phd/misc-scripts/hpcv2/hpc_jobs/rrn_equal_abl_rep/JACK_$count  \\n      count=`expr $count + 1`\\n\\n      #script=\"source /usr/share/Modules/3.2.10/init/bash && CUDA_VISIBLE_DEVICES=1 nohup /home/yatin/phd/misc-scripts/hpcv2/hpc_jobs/rrn_equal_abl_rep/exp_${count}.sh > /home/yatin/phd/misc-scripts/hpcv2/hpc_jobs/rrn_equal_abl_rep/LOG_${count} 2>&1 &\"\\n      script=\"CUDA_VISIBLE_DEVICES=1 nohup /home/yatin/phd/misc-scripts/hpcv2/hpc_jobs/rrn_equal_abl_rep/exp_${count}.sh > /home/yatin/phd/misc-scripts/hpcv2/hpc_jobs/rrn_equal_abl_rep/LOG_${count} 2>&1 &\"\\n      echo $script\\n      ssh -o StrictHostKeyChecking=no -n -f ${USER}@$p $script  \\n      var[`expr $count - $init_count`]=/home/yatin/phd/misc-scripts/hpcv2/hpc_jobs/rrn_equal_abl_rep/JACK_$count  \\n      count=`expr $count + 1`\\n  \\ndone <$PBS_NODEFILE\\n\\nfor i in \"${var[@]}\" \\ndo \\n\\techo $i \\n    until [ -f $i ]\\n    do\\n        sleep 10\\n    done\\n\\ndone \\n\\n\\n\\n'],\n",
      "      dtype='|S2206')]\n",
      "2 [11703, array([b'#!/bin/bash\\n#BSUB -J node_pong\\n#BSUB -e node_pong.%J.err\\n#BSUB -o node_pong.%J.out\\n#BSUB -nnodes 2\\n#BSUB -q pdebug\\n#BSUB -W 00:15\\n\\nmodule load gcc\\nmodule load cuda\\n\\ncd /g/g14/bienz1/BenchPress/spectrum_build/examples\\n\\nnvidia-cuda-mps-control -d\\n\\njsrun -a40 -c40 -g4 -r1 -n2 -M \"-gpu\" --latency_priority=gpu-cpu --launch_distribution=packed --print_placement=1 ./time_node_pong\\n\\necho quit | nvidia-cuda-mps-control\\n\\n\\n\\n'],\n",
      "      dtype='|S417')]\n",
      "2 [40733, array([b'#!/usr/bin/env bash\\n#\\n# Slurm arguments.\\n#\\n#SBATCH --cpus-per-task=1\\n#SBATCH --export=ALL\\n#SBATCH --job-name \"STREAM_INFERENCE_ABC_GD1_NEW\"\\n#SBATCH --mem-per-cpu=4000\\n#SBATCH --ntasks=1\\n#SBATCH --output \"logging/abc_gd1_new.log\"\\n#SBATCH --parsable\\n#SBATCH --requeue\\n#SBATCH --time=\"1-00:00:00\"\\n#\\n\\nsuffix=$(printf \"%05d\" $SLURM_ARRAY_TASK_ID)\\nout=$BASE/out/gd1/abc-new-$suffix\\nmkdir -p $out\\n\\n# Check if the procedure already completed\\nif [ ! -f $out/samples.npy -o $PROJECT_FORCE_RERUN -ne 0 ]; then\\n    python -u abc-new.py \\\\\\n           --average \\\\\\n           --auto \\\\\\n           --threshold $EXPERIMENT_ABC_THRESHOLD \\\\\\n           --ages $DATADIR/train/ages-r.npy \\\\\\n           --masses $DATADIR/train/masses-r.npy \\\\\\n           --observations $DATADIR/observed-noised.npy \\\\\\n           --out $out \\\\\\n           --outputs $DATADIR/train/density-contrasts-cut-noised.npy\\nfi\\n'],\n",
      "      dtype='|S869')]\n",
      "2 [28674, array([b'#!/bin/bash\\n#SBATCH --job-name=vmcts\\n#SBATCH --output=/n/holyscratch01/kempner_fellows/Users/dbrandfonbrener/vmcts/logs/%A_%a.out\\n#SBATCH --nodes=1              \\n#SBATCH --ntasks-per-node=1\\n#SBATCH --gpus-per-node=1    \\n#SBATCH --cpus-per-task=16\\n#SBATCH --time=8:00:00\\n#SBATCH --mem=250GB\\t\\t\\n#SBATCH --account=kempner_fellows\\n#SBATCH --partition=kempner\\n#SBATCH --constraint=a100\\n#SBATCH --array=0-4\\n\\n# Custom environment\\nsource ~/.bashrc\\nconda deactivate\\nconda activate verify\\n\\nexport PYTHONPATH=.:${PYTHONPATH}\\n\\nexport model_arg_temps=(0.2 0.4 0.6 0.8 1.0)\\nexport model_arg_topp=0.95\\nexport model_arg_topk=0\\n\\nexport n_samples=1000 # probably will hit time limit before this\\n\\nexport run_number=$[$SLURM_ARRAY_TASK_ID/5] # 100 runs per hyperparameter\\nexport hyperparam_number=$[$SLURM_ARRAY_TASK_ID%5]\\nexport model_arg_temp_idx=$[$hyperparam_number]\\nexport model_arg_temp=${model_arg_temps[$model_arg_temp_idx]}\\n\\nexport WANDB_USERNAME=seas\\nexport WANDB_PROJECT=vmcts\\nexport WANDB_GROUP=whole-sweep-3\\nexport WANDB_NAME=$run_number/$model_arg_temp\\n\\nSEED=$run_number\\n\\necho Using seed: $SEED\\necho Run number: $run_number\\necho Temp: $model_arg_temp\\necho Top p: $model_arg_topp\\n\\npython run_whole.py --seed=$SEED --use_wandb=True --wandb_entity=$WANDB_USERNAME --wandb_project=$WANDB_PROJECT --wandb_group=$WANDB_GROUP --wandb_name=$WANDB_NAME --remove_hints=True --model_arg_temp=$model_arg_temp --model_arg_topp=$model_arg_topp --model_arg_topk=$model_arg_topk --n_samples=$n_samples\\n\\n'],\n",
      "      dtype='|S1480')]\n",
      "2 [14591, array([b'#!/bin/bash\\n#SBATCH --job-name=fastpbf_2D\\n#SBATCH --output=out/out_fastpbf_2D.out\\n#SBATCH --error=err/err_fastpbf_2D.err\\n#SBATCH --time=16:00:00\\n#SBATCH --partition=bigmem\\n#SBATCH --qos=bigmem\\n#SBATCH --nodes=1\\n#SBATCH --mem=1500000\\n#################\\n\\nmodule load matlab\\ncd ../../test/fio\\nmatlab -nojvm -r \"batch_fastpbf_2D;quit\"\\n'],\n",
      "      dtype='|S330')]\n",
      "2 [36101, array([b'#!/bin/bash\\n#COBALT -n 1\\n#COBALT -t 1:00:00\\n#COBALT -q training-knl --attrs mcdram=cache:numa=quad\\n#COBALT -A SDL_Workshop\\n\\necho \"Running Cobalt Job $COBALT_JOBID.\"\\n\\n#Load modules\\nmodule load datascience/pytorch-1.4\\nmodule load vtune/latest\\n\\n## Set libraries\\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/compilers/intel/19.0.3.199/vtune_amplifier/lib64/\\n\\n## set proxies\\nexport https_proxy=https://proxy.tmi.alcf.anl.gov:3128\\nexport http_proxy=http://proxy.tmi.alcf.anl.gov:3128\\n\\n## run the job\\nPROC_PER_NODE=1\\n#aprun -n $(($COBALT_JOBSIZE*$PROC_PER_NODE)) -N $PROC_PER_NODE python pytorch_cifar10.py --device cpu --epochs 5\\n\\n## use Intel Vtune APS to get application performance snapshot\\naprun -n $(($COBALT_JOBSIZE*$PROC_PER_NODE)) -N $PROC_PER_NODE aps python pytorch_cifar10.py --device cpu --epochs 5\\naps --report=./aps_result_20201202\\n\\n## Use Intel Vtune to extract hotspots\\naprun -n $(($COBALT_JOBSIZE*$PROC_PER_NODE)) -N $PROC_PER_NODE  amplxe-cl -c hotspots -finalization-mode=none -knob sampling-mode=hw -r vtune-result-dir_advancedhotspots -strategy ldconfig:notrace:notrace --  python pytorch_cifar10.py --device cpu --epochs 1\\n\\n## (B) From login node\\n# amplxe-cl -finalize -search-dir / -r vtune-result-dir_advancedhotspots\\n\\n## steps to visualize results\\n## (C) tunnel with ssh -XL to run GUI or copy to local machine\\n# amplxe-gui  vtune-result-dir_advancedhotspots\\n\\n'],\n",
      "      dtype='|S1380')]\n",
      "2 [33432, array([b'#!/usr/bin/env bash\\n\\n#SBATCH --job-name=ior@3.3.0\\n#SBATCH --account=sys200\\n#SBATCH --partition=hotel-gpu\\n#SBATCH --nodes=1\\n#SBATCH --ntasks-per-node=1\\n#SBATCH --cpus-per-task=8\\n#SBATCH --time=00:30:00\\n#SBATCH --output=%x.o%j.%N\\n\\ndeclare -xr LOCAL_TIME=\"$(date +\\'%Y%m%dT%H%M%S%z\\')\"\\ndeclare -xir UNIX_TIME=\"$(date +\\'%s\\')\"\\n\\ndeclare -xr SYSTEM_NAME=\\'tscc\\'\\n\\ndeclare -xr SPACK_VERSION=\\'0.17.3\\'\\ndeclare -xr SPACK_INSTANCE_NAME=\\'gpu\\'\\ndeclare -xr SPACK_INSTANCE_DIR=\"/home/jpg/cm/shared/apps/spack/${SPACK_VERSION}/${SPACK_INSTANCE_NAME}\"\\n\\ndeclare -xr SLURM_JOB_SCRIPT=\"$(scontrol show job ${SLURM_JOB_ID} | awk -F= \\'/Command=/{print $2}\\')\"\\ndeclare -xr SLURM_JOB_MD5SUM=\"$(md5sum ${SLURM_JOB_SCRIPT})\"\\n\\ndeclare -xr SCHEDULER_MODULE=\\'slurm/tscc/current\\'\\n\\necho \"${UNIX_TIME} ${SLURM_JOB_ID} ${SLURM_JOB_MD5SUM} ${SLURM_JOB_DEPENDENCY}\" \\necho \"\"\\n\\ncat \"${SLURM_JOB_SCRIPT}\"\\ndeclare -xr COMPILER_MODULE=\\'intel/19.1.1.217\\'\\n\\nmodule purge\\nmodule load \"${SCHEDULER_MODULE}\"\\nmodule load ${SPACK_INSTANCE_NAME}\\nmodule load ${COMPILER_MODULE}\\nmodule list\\n. \"${SPACK_INSTANCE_DIR}/share/spack/setup-env.sh\"\\n\\ndeclare -xr INTEL_LICENSE_FILE=\\'40000@elprado.sdsc.edu:40200@elprado.sdsc.edu\\'\\ndeclare -xr SPACK_PACKAGE=\\'ior@3.3.0\\'\\ndeclare -xr SPACK_COMPILER=\\'intel@19.1.1.217\\'\\ndeclare -xr SPACK_VARIANTS=\\'+hdf5 +ncmpi\\'\\ndeclare -xr SPACK_DEPENDENCIES=\"^openmpi@4.1.3/$(spack find --format \\'{hash:7}\\' openmpi@4.1.3 % ${SPACK_COMPILER}) ^hdf5@1.10.7/$(spack find --format \\'{hash:7}\\' hdf5@1.10.7 % ${SPACK_COMPILER} +mpi ^openmpi@4.1.3) ^parallel-netcdf@1.12.2/$(spack find --format \\'{hash:7}\\' parallel-netcdf@1.12.2 % ${SPACK_COMPILER} ^openmpi@4.1.3)\"\\ndeclare -xr SPACK_SPEC=\"${SPACK_PACKAGE} % ${SPACK_COMPILER} ${SPACK_VARIANTS} ${SPACK_DEPENDENCIES}\"\\n\\nprintenv\\n\\nspack config get compilers  \\nspack config get config  \\nspack config get mirrors\\nspack config get modules\\nspack config get packages\\nspack config get repos\\nspack config get upstreams\\n\\nspack spec --long --namespaces --types \"${SPACK_SPEC}\"\\nif [[ \"${?}\" -ne 0 ]]; then\\n  echo \\'ERROR: spack concretization failed.\\'\\n  exit 1\\nfi\\n\\ntime -p spack install --jobs \"${SLURM_CPUS_PER_TASK}\" --fail-fast --yes-to-all \"${SPACK_SPEC}\"\\nif [[ \"${?}\" -ne 0 ]]; then\\n  echo \\'ERROR: spack install failed.\\'\\n  exit 1\\nfi\\n\\n#spack module lmod refresh --delete-tree -y\\n\\nsbatch --dependency=\"afterok:${SLURM_JOB_ID}\" \\'netcdf-c@4.8.1.sh\\'\\n\\nsleep 20\\n'],\n",
      "      dtype='|S2353')]\n",
      "2 [11642, array([b\"dataset_params:\\n  root_dir: ../../Data/Face_Generation/SAMM/SAMM_fom\\n  frame_shape: [256, 256, 3]\\n  id_sampling: False\\n  # pairs_list: data/vox256.csv\\n  augmentation_params:\\n    flip_param:\\n      horizontal_flip: True\\n      time_flip: True\\n    jitter_param:\\n      brightness: 0.1\\n      contrast: 0.1\\n      saturation: 0.1\\n      hue: 0.1\\n\\n\\nmodel_params:\\n  common_params:\\n    num_kp: 10\\n    num_channels: 3\\n    estimate_jacobian: True\\n  kp_detector_params:\\n     temperature: 0.1\\n     block_expansion: 32\\n     max_features: 1024\\n     scale_factor: 0.25\\n     num_blocks: 5\\n  generator_params:\\n    block_expansion: 64\\n    max_features: 512\\n    num_down_blocks: 2\\n    num_bottleneck_blocks: 6\\n    estimate_occlusion_map: True\\n    dense_motion_params:\\n      block_expansion: 64\\n      max_features: 1024\\n      num_blocks: 5\\n      scale_factor: 0.25\\n  discriminator_params:\\n    scales: [1]\\n    block_expansion: 32\\n    max_features: 512\\n    num_blocks: 4\\n    sn: True\\n\\ntrain_params:\\n  num_epochs: 500\\n  num_repeats: 75\\n  epoch_milestones: [60, 90]\\n  lr_generator: 2.0e-4\\n  lr_discriminator: 2.0e-4\\n  lr_kp_detector: 2.0e-4\\n  batch_size: 30\\n  scales: [1, 0.5, 0.25, 0.125]\\n  checkpoint_freq: 50\\n  transform_params:\\n    sigma_affine: 0.05\\n    sigma_tps: 0.005\\n    points_tps: 5\\n  loss_weights:\\n    generator_gan: 0\\n    discriminator_gan: 1\\n    feature_matching: [10, 10, 10, 10]\\n    perceptual: [10, 10, 10, 10, 10]\\n    equivariance_value: 10\\n    equivariance_jacobian: 10\\n\\nreconstruction_params:\\n  num_videos: 1000\\n  format: '.mp4'\\n\\nanimate_params:\\n  num_pairs: 50\\n  format: '.mp4'\\n  normalization_params:\\n    adapt_movement_scale: False\\n    use_relative_movement: True\\n    use_relative_jacobian: True\\n\\nvisualizer_params:\\n  kp_size: 5\\n  draw_border: True\\n  colormap: 'gist_rainbow'\\n\"],\n",
      "      dtype='|S1771')]\n",
      "2 [36389, array([b'#!/bin/bash\\n#SBATCH --job-name=data-proc\\n#SBATCH --partition=gpu-a40\\n#SBATCH --account=cse\\n#SBATCH --nodes=1\\n#SBATCH --cpus-per-task=8\\n#SBATCH --mem=32G\\n#SBATCH --gres=gpu:1\\n#SBATCH --time=04:59:00\\n#SBATCH --mail-type=ALL\\n#SBATCH --mail-user=tjung2@uw.edu\\n\\n# I use source to initialize conda into the right environment.\\ncat $0\\necho \"--------------------\"\\n\\nsource ~/.bashrc\\nconda activate ckl\\n\\npython run.py --config configs/templama/evaluation/t5_kadapters_large.json\\n--------------------\\n/mmfs1/gscratch/ark/tjung2/miniconda3/envs/ckl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:396: LightningDeprecationWarning: Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5. Please use `every_n_val_epochs` instead.\\n  rank_zero_deprecation(\\nSome weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/t5-large-ssm and are newly initialized: [\\'kadapter.adapter.1.layer.0.layer_norm.weight\\', \\'kadapter.adapter.0.layer.1.DenseReluDense.wi.weight\\', \\'kadapter.adapter.1.layer.0.SelfAttention.k.weight\\', \\'kadapter.adapter.0.layer.1.DenseReluDense.wo.weight\\', \\'kadapter.adapter.0.layer.0.SelfAttention.k.weight\\', \\'kadapter.adapter.1.layer.1.DenseReluDense.wi.weight\\', \\'kadapter.adapter.1.layer.0.SelfAttention.q.weight\\', \\'kadapter.adapter.0.layer.0.SelfAttention.v.weight\\', \\'kadapter.adapter.0.layer.0.layer_norm.weight\\', \\'kadapter.adapter.0.layer.0.SelfAttention.o.weight\\', \\'kadapter.adapter.1.layer.0.SelfAttention.o.weight\\', \\'kadapter.adapter.1.layer.1.layer_norm.weight\\', \\'kadapter.adapter.1.layer.0.SelfAttention.v.weight\\', \\'kadapter.adapter.1.layer.1.DenseReluDense.wo.weight\\', \\'kadapter.adapter.0.layer.0.SelfAttention.q.weight\\', \\'kadapter.adapter.0.layer.1.layer_norm.weight\\', \\'kadapter.adapter.0.layer.0.SelfAttention.relative_attention_bias.weight\\', \\'kadapter.layer_norm.weight\\']\\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\\nSome weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/t5-large-ssm and are newly initialized: [\\'kadapter.adapter.1.layer.0.layer_norm.weight\\', \\'kadapter.adapter.0.layer.1.DenseReluDense.wi.weight\\', \\'kadapter.adapter.1.layer.0.SelfAttention.k.weight\\', \\'kadapter.adapter.0.layer.1.DenseReluDense.wo.weight\\', \\'kadapter.adapter.0.layer.0.SelfAttention.k.weight\\', \\'kadapter.adapter.1.layer.1.DenseReluDense.wi.weight\\', \\'kadapter.adapter.1.layer.0.SelfAttention.q.weight\\', \\'kadapter.adapter.0.layer.0.SelfAttention.v.weight\\', \\'kadapter.adapter.0.layer.0.layer_norm.weight\\', \\'kadapter.adapter.0.layer.0.SelfAttention.o.weight\\', \\'kadapter.adapter.1.layer.0.SelfAttention.o.weight\\', \\'kadapter.adapter.1.layer.1.layer_norm.weight\\', \\'kadapter.adapter.1.layer.0.SelfAttention.v.weight\\', \\'kadapter.adapter.1.layer.1.DenseReluDense.wo.weight\\', \\'kadapter.adapter.0.layer.0.SelfAttention.q.weight\\', \\'kadapter.adapter.0.layer.1.layer_norm.weight\\', \\'kadapter.adapter.0.layer.0.SelfAttention.relative_attention_bias.weight\\', \\'kadapter.layer_norm.weight\\']\\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\\nNot freezing any parameters!\\nNot freezing any parameters!\\nsplit is 0\\nLength of dataset retrieving is.. 376\\nLength of validation data:  376\\nlog/templama folder already exists.\\nNumber of total validation data: 376\\nNumber of correct predictions: 4. Percentage : 0.010638297872340425\\n'],\n",
      "      dtype='|S3468')]\n",
      "2 [21123, array([b'#!/bin/bash\\n# --------------------------------------------------------------------------- #\\n# matrix.go: Run matrix of regression tests on target machine.                #\\n#                                                                             #\\n# Remarks:                                                                    #\\n# - This version is set up for automatic w3_setenv script and for the         #\\n#   NOAA RDHPC systems. When using this for your own setup and                #\\n#   computer, please copy rather than modify.                                 #\\n#                                                                             #\\n#                                                      Hendrik L. Tolman      #\\n#                                                      August 2013            #\\n#                                            Last update:   May 2022          #\\n#                                                                             #\\n#    Copyright 2013 National Weather Service (NWS),                           #\\n#       National Oceanic and Atmospheric Administration.  All rights          #\\n#       reserved.  WAVEWATCH III is a trademark of the NWS.                   #\\n#       No unauthorized use without permission.                               #\\n#                                                                             #\\n# --------------------------------------------------------------------------- #\\n\\nusage ()\\n{\\n  cat 2>&1 << EOF\\n\\n  Usage: $myname model_dir\\n  Required:\\n    model_dir : path to model dir of WW3 source\\nEOF\\n}\\n\\n\\n# Get required arguments\\n  if [ ! $# = 0 ]\\n  then\\n    main_dir=\"$1\" ; shift\\n  else\\n    usage\\n    exit 1\\n  fi\\n\\n# Convert main_dir to absolute path\\n  main_dir=\"`cd $main_dir 1>/dev/null 2>&1 && pwd`\"\\n\\n# Module Versions from HPC-Stack that are common for all platforms\\n  modnetcdf=\\'netcdf/4.7.4\\'\\n  modjasper=\\'jasper/2.0.25\\'\\n  modzlib=\\'zlib/1.2.11\\'\\n  modpng=\\'libpng/1.6.37\\'\\n  modhdf5=\\'hdf5/1.10.6\\'\\n  modbacio=\\'bacio/2.4.1\\'\\n  modg2=\\'g2/3.4.5\\'\\n  modw3emc=\\'w3emc/2.9.2\\'\\n  modesmf=\\'esmf/8.3.0b09\\'\\n\\n# Set batchq queue, choose modules and other custom variables to fit system and\\n# to define headers etc (default to original version if empty)\\n  ishera=`hostname | grep hfe`\\n  isorion=`hostname | grep Orion`\\n  if [ $ishera ]\\n  then\\n    # If no other h, assuming Hera\\n    batchq=\\'slurm\\'\\n    basemodcomp=\\'intel/2022.1.2\\'\\n    basemodmpi=\\'impi/2022.1.2\\'\\n    hpcstackpath=\\'/scratch1/NCEPDEV/nems/role.epic/hpc-stack/libs/intel-2022.1.2/modulefiles/stack\\'\\n    hpcstackversion=\\'hpc/1.2.0\\'\\n    modcomp=\\'hpc-intel/2022.1.2\\'\\n    modmpi=\\'hpc-impi/2022.1.2\\'\\n    scotchpath=\\'/scratch1/NCEPDEV/climate/Matthew.Masarik/waves/opt/hpc-stack/scotch-v7.0.3/install\\'\\n    metispath=\\'/scratch1/NCEPDEV/climate/Matthew.Masarik/waves/opt/hpc-stack/parmetis-4.0.3/install\\'\\n    modcmake=\\'cmake/3.20.1\\'\\n  elif [ $isorion ]\\n  then\\n    batchq=\\'slurm\\'\\n    basemodcomp=\\'intel/2022.1.2\\'\\n    basemodmpi=\\'impi/2022.1.2\\'\\n    hpcstackpath=\\'/work/noaa/epic-ps/hpc-stack/libs/intel/2022.1.2/modulefiles/stack\\'\\n    hpcstackversion=\\'hpc/1.2.0\\'\\n    modcomp=\\'hpc-intel/2022.1.2\\'\\n    modmpi=\\'hpc-impi/2022.1.2\\'\\n    scotchpath=\\'/work2/noaa/marine/mmasarik/waves/opt/hpc-stack/scotch-v7.0.3/install\\'\\n    metispath=\\'/work2/noaa/marine/mmasarik/waves/opt/hpc-stack/parmetis-4.0.3/install\\'\\n    modcmake=\\'cmake/3.22.1\\'\\n  else\\n    batchq=\\n  fi\\n\\n# 1. Set up\\n\\n  export np=\\'24\\'      #number of mpi tasks\\n  export npl=\\'140\\'    #number of mpi tasks for ufs applications and large setups\\n  export npl1=\\'100\\'   #number of mpi tasks for ufs/large setups (b4b check)\\n  export nr=\\'4\\'       #number of mpi tasks for hybrid\\n  export nth=\\'6\\'      #number of threads\\n  export nth1=\\'4\\'     #number of threads (b4b check)\\n\\n# 1.a Computer/ user dependent set up\\n\\n  echo \\'#!/bin/sh --login\\'                                   > matrix.head\\n  echo \\' \\'                                                  >> matrix.head\\n  if [ $batchq = \"slurm\" ] && [ $isorion ]\\n  then\\n    echo \"#SBATCH -n ${np}\"                                 >> matrix.head\\n    echo \"##SBATCH --cpus-per-task=${nth}\"                  >> matrix.head\\n    echo \\'#SBATCH -q batch\\'                                 >> matrix.head\\n    echo \\'#SBATCH -t 08:00:00\\'                              >> matrix.head\\n    echo \\'#SBATCH -A marine-cpu\\'                            >> matrix.head\\n    echo \\'#SBATCH -J ww3_regtest\\'                           >> matrix.head\\n    echo \\'#SBATCH -o matrix.out\\'                            >> matrix.head\\n    echo \\'#SBATCH -p orion\\'                                 >> matrix.head\\n    echo \\'#SBATCH --exclusive\\'                              >> matrix.head\\n    echo \\' \\'                                                >> matrix.head\\n    echo \\'ulimit -s unlimited\\'                              >> matrix.head\\n    echo \\'ulimit -c 0\\'                                      >> matrix.head\\n    echo \\'export KMP_STACKSIZE=2G\\'                          >> matrix.head\\n    echo \\'export FI_OFI_RXM_BUFFER_SIZE=128000\\'             >> matrix.head\\n    echo \\'export FI_OFI_RXM_RX_SIZE=64000\\'                  >> matrix.head\\n  elif [ $batchq = \"slurm\" ]\\n  then\\n    echo \"#SBATCH -n ${np}\"                                 >> matrix.head\\n    echo \"##SBATCH --cpus-per-task=${nth}\"                  >> matrix.head\\n    echo \\'#SBATCH -q batch\\'                                 >> matrix.head\\n    echo \\'#SBATCH -t 08:00:00\\'                              >> matrix.head\\n    echo \\'#SBATCH -A marine-cpu\\'                            >> matrix.head\\n    echo \\'#SBATCH -J ww3_regtest\\'                           >> matrix.head\\n    echo \\'#SBATCH -o matrix.out\\'                            >> matrix.head\\n  else\\n    echo \\'#PBS -l procs=24\\'                                 >> matrix.head\\n    echo \\'#PBS -q batch\\'                                    >> matrix.head\\n    echo \\'#PBS -l walltime=08:00:00\\'                        >> matrix.head\\n    echo \\'#PBS -A marine-cpu\\'                               >> matrix.head\\n    echo \\'#PBS -N ww3_regtest\\'                              >> matrix.head\\n    echo \\'#PBS -j oe\\'                                       >> matrix.head\\n    echo \\'#PBS -o matrix.out\\'                               >> matrix.head\\n  fi\\n  echo \\' \\'                                                  >> matrix.head\\n  echo \"  cd $(dirname $main_dir)/regtests\"                 >> matrix.head\\n  echo \\' \\'                                                  >> matrix.head\\n\\n# Netcdf, Parmetis and SCOTCH modules & variables\\n  echo \"  module purge\"                                     >> matrix.head\\n  echo \"  module load $modcmake\"                            >> matrix.head\\n  if [ ! -z $basemodcomp ]; then\\n    echo \"  module load $basemodcomp\"                       >> matrix.head\\n  fi\\n  if [ ! -z $basemodmpi ]; then\\n    echo \"  module load $basemodmpi\"                        >> matrix.head\\n  fi\\n  echo \"  module use  $hpcstackpath\"                        >> matrix.head\\n  echo \"  module load $hpcstackversion\"                     >> matrix.head\\n  echo \"  module load $modcomp\"                             >> matrix.head\\n  echo \"  module load $modmpi\"                              >> matrix.head\\n  echo \"  module load $modpng\"                              >> matrix.head\\n  echo \"  module load $modzlib\"                             >> matrix.head\\n  echo \"  module load $modjasper\"                           >> matrix.head\\n  echo \"  module load $modhdf5\"                             >> matrix.head\\n  echo \"  module load $modnetcdf\"                           >> matrix.head\\n  echo \"  module load $modbacio\"                            >> matrix.head\\n  echo \"  module load $modg2\"                               >> matrix.head\\n  echo \"  module load $modw3emc\"                            >> matrix.head\\n  echo \"  module load $modesmf\"                             >> matrix.head\\n\\n  echo \"  export METIS_PATH=${metispath}\"                   >> matrix.head\\n  echo \"  export SCOTCH_PATH=${scotchpath}\"                 >> matrix.head\\n  echo \"  export path_build_root=$(dirname $main_dir)/regtests/buildmatrix\" >> matrix.head\\n  echo \\'  [[ -d ${path_build_root} ]] && rm -rf ${path_build_root}\\'         >> matrix.head\\n  echo \\' \\'\\n\\n  if [ \"$batchq\" = \\'slurm\\' ]\\n  then\\n    export  mpi=\\'srun\\'\\n  else\\n    export  mpi=\\'mpirun\\'\\n  fi\\n\\n# Compile option\\n  opt=\"-o all -S -T\"\\n\\n# Batch queue option\\n  if [ \"$batchq\" = \\'slurm\\' ]\\n  then\\n     opt=\"-b $batchq $opt\"\\n  fi\\n\\n# Base run_test command line\\n  export rtst=\"./bin/run_cmake_test $opt\"\\n\\n  export  ww3=\\'../model\\'\\n\\n# 1.b Flags to do course selection - - - - - - - - - - - - - - - - - - - - - -\\n#     Addition selection by commenting out lines as below\\n\\n  export       shrd=\\'y\\' # Do shared architecture tests\\n  export       dist=\\'y\\' # Do distributed architecture (MPI) tests\\n  export        omp=\\'y\\' # Threaded (OpenMP) tests\\n  export       hybd=\\'y\\' # Hybrid options\\n\\n  export     prop1D=\\'y\\' # 1-D propagation tests (ww3_tp1.X)\\n  export     prop2D=\\'y\\' # 2-D propagation tests (ww3_tp2.X)\\n  export       time=\\'y\\' # time linmited growth\\n  export      fetch=\\'y\\' # fetch linmited growth\\n  export     hur1mg=\\'y\\' # Hurricane with one moving grid\\n  export      shwtr=\\'y\\' # shallow water tests\\n  export      unstr=\\'y\\' # unstructured grid tests\\n  export      pdlib=\\'y\\' # unstr with pdlib for domain decomposition and implicit solver\\n  export      smcgr=\\'y\\' # SMC grid test\\n  export        rtd=\\'y\\' # Rotated pole test\\n  export     mudice=\\'y\\' # Mud/Ice and wave interaction tests\\n  export     infgrv=\\'y\\' # Second harmonic generation tests\\n  export       uost=\\'y\\' # ww3_ts4 Unresolved Obstacles Source Term (UOST)\\n  export      assim=\\'y\\' # Restart spectra update\\n  export      oasis=\\'y\\' # Atmosphere, ocean, and ice coupling using OASIS\\n  export   calendar=\\'y\\' # Calendar type\\n  export   confignc=\\'y\\' # Configurable netCDF meta data (ww3_ounf)\\n\\n  export    multi01=\\'y\\' # mww3_test_01 (wetting and drying)\\n  export    multi02=\\'y\\' # mww3_test_02 (basic two-way nesting test))\\n  export    multi03=\\'y\\' # mww3_test_03 (three high and three low res grids).\\n  export    multi04=\\'y\\' # mww3_test_04 (swell on sea mount and/or current)\\n  export    multi05=\\'y\\' # mww3_test_05 (three-grid moving hurricane)\\n  export    multi06=\\'y\\' # mww3_test_06 (curvilinear grid tests)\\n  export    multi07=\\'y\\' # mww3_test_07 (unstructured grid tests)\\n  export    multi08=\\'y\\' # mww3_test_08 (wind and ice tests)\\n  export    multi09=\\'y\\' # mww3_test_09 (SMC multi grid test)\\n\\n  export        ufs=\\'y\\' # The Unified Forecast System\\n  export  ufscoarse=\\'y\\' # Option for small PCs\\n  export       grib=\\'y\\' # grib file field output\\n  export  rstrt_b4b=\\'y\\' # Restart Reproducibility\\n  export    npl_b4b=\\'y\\' # MPI task Reproducibility\\n  export    nth_b4b=\\'y\\' # Thread Reproducibility\\n  export       esmf=\\'n\\' # ESMF coupling\\n# export   filter=\\'PR3 ST2 UQ\\'\\n                      # The filter does a set of consecutive greps on the\\n                      # command lines generated by filter.base with the above\\n                      # selected options.\\n\\n# --------------------------------------------------------------------------- #\\n# 2.  Execute matrix.base ...                                                 #\\n# --------------------------------------------------------------------------- #\\n\\n  $main_dir/../regtests/bin/matrix.base\\n\\n  $main_dir/../regtests/bin/matrix_divider_cmake.sh\\n\\n\\n  echo \"#submit all of the diveded matrix files\" > msuball.sh\\n  if [ $batchq = \"slurm\" ]\\n  then\\n    files=`ls matrix??`\\n    for file in $files\\n    do\\n      echo \"sbatch < $file\"  >> msuball.sh\\n    done\\n  fi\\n\\n# --------------------------------------------------------------------------- #\\n# End to the matrix                                                           #\\n# --------------------------------------------------------------------------- #\\n'],\n",
      "      dtype='|S11749')]\n",
      "2 [18735, array([b'#!/bin/bash\\n\\n#SBATCH --time=72:00:00   # walltime\\n#SBATCH --ntasks=3   # number of processor cores (i.e. tasks)\\n#SBATCH --gpus=1\\n\\nset -e\\n\\neval \"$(conda shell.bash hook)\"\\nconda activate FACIL\\n\\nnum_tasks=26\\nnc_first_task=100\\nnum_epochs=200\\ndataset=tiny_scaled_imnet\\nnetwork=resnet32\\ntag=tin_t${num_tasks}s${nc_first_task}\\n\\nlamb_tw=1.0\\nlamb_mc=0.5\\nlamb=10\\n\\nfor wu_nepochs in 0 200; do\\n  for seed in 0 1 2; do\\n    ./experiments/lwf.sh 0 ${seed} ${tag} ${dataset} ${num_tasks} ${nc_first_task} ${network} ${num_epochs} ${lamb} ${wu_nepochs} &\\n  done\\n  wait\\n\\n  for seed in 0 1 2; do\\n    ./experiments/lwf_ta.sh 0 ${seed} ${tag} ${dataset} ${num_tasks} ${nc_first_task} ${network} ${num_epochs} ${lamb} ${wu_nepochs} &\\n  done\\n  wait\\n\\n  for seed in 0 1 2; do\\n    ./experiments/lwf_mc.sh 0 ${seed} ${tag} ${dataset} ${num_tasks} ${nc_first_task} ${network} ${num_epochs} ${lamb_mc} ${wu_nepochs} &\\n  done\\n  wait\\n\\n  for seed in 0 1 2; do\\n    ./experiments/lwf_mc_ta.sh 0 ${seed} ${tag} ${dataset} ${num_tasks} ${nc_first_task} ${network} ${num_epochs} ${lamb_mc} ${wu_nepochs} &\\n  done\\n  wait\\n\\n  for seed in 0 1 2; do\\n    ./experiments/lwf_tw.sh 0 ${seed} ${tag} ${dataset} ${num_tasks} ${nc_first_task} ${network} ${num_epochs} ${lamb_tw} ${wu_nepochs} &\\n  done\\n  wait\\n\\n  for seed in 0 1 2; do\\n    ./experiments/lwf_tw_ta.sh 0 ${seed} ${tag} ${dataset} ${num_tasks} ${nc_first_task} ${network} ${num_epochs} ${lamb_tw} ${wu_nepochs} &\\n  done\\n  wait\\n\\n  for seed in 0 1 2; do\\n    ./experiments/lwfa.sh 0 ${seed} ${tag} ${dataset} ${num_tasks} ${nc_first_task} ${network} ${num_epochs} ${lamb} ${wu_nepochs} &\\n  done\\n  wait\\n\\n  for seed in 0 1 2; do\\n    ./experiments/lwfa_ta.sh 0 ${seed} ${tag} ${dataset} ${num_tasks} ${nc_first_task} ${network} ${num_epochs} ${lamb} ${wu_nepochs} &\\n  done\\n  wait\\ndone\\n'],\n",
      "      dtype='|S1792')]\n",
      "2 [15756, array([b'#!/bin/bash\\n#\\n#SBATCH --job-name=uresnet_finetuning\\n#SBATCH --output=uresnet_finetuning.log\\n#SBATCH --ntasks=1\\n#SBATCH --time=1-00:00:00\\n#SBATCH --mem-per-cpu=8000\\n#SBATCH --cpus-per-task=2\\n#SBATCH --partition gpu\\n#SBATCH --nodelist=pgpu03\\n\\n\\nWORKDIR=/cluster/kappa/90-days-archive/wongjiradlab/twongj01/pytorch-uresnet\\nDATADIR=/cluster/kappa/90-days-archive/wongjiradlab/twongj01/ssnet_training_data\\nCONTAINER=/cluster/kappa/90-days-archive/wongjiradlab/larbys/images/singularity-larbys-pytorch/singularity-larbys-pytorch-larcv1-nvidia384.66.img\\n\\nmodule load singularity\\nsingularity exec --nv ${CONTAINER} bash -c \"cd ${WORKDIR} && source run_finetuning_job.sh ${WORKDIR} ${DATADIR}\"'],\n",
      "      dtype='|S683')]\n"
     ]
    }
   ],
   "source": [
    "batches = 0\n",
    "for batch in my_dataset:\n",
    "    print(len(batch), batch)\n",
    "    if batches > 10:\n",
    "        break\n",
    "    batches = batches + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

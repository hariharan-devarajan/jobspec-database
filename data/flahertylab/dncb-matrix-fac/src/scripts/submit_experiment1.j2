#!/bin/bash
#SBATCH --job-name={{ experiment_name }}
#SBATCH -w c0
#SBATCH --nodes={{ num_nodes }}
#SBATCH --ntasks-per-node={{ num_tasks_per_node }}
#SBATCH --array=0-{{ array_range }}
#SBATCH --error=./results/experiment_1/errorlog-%j.err

DOCKER_IMAGE=dncb-fac-image
CONTAINER_NAME=dncb-fac-container

MLFLOW_EXPERIMENT_NAME=experiment_1

# Load necessary modules
module load jq

# Read the job configuration from the JSON file
job_config_file="{{ experiment_config_json }}"
{% raw %}
job_config=$(jq -r ".[${SLURM_ARRAY_TASK_ID}]" $job_config_file)

# Extract the individual configuration values
data_path=$(echo $job_config | jq -r ".data_path")
#job_name=$(echo $job_config | jq -r ".job_name")
#num_nodes=$(echo $job_config | jq -r ".num_nodes")
#num_tasks_per_node=$(echo $job_config | jq -r ".num_tasks_per_node")
uuid=$(echo $job_config | jq -r ".uuid")

# Run the Docker container
#docker image pull oak:6000/dncb-fac-image

docker run --rm -v /data/projects/dncbtd:/work/data -v ./${uuid}:/work/data/tmp  \
    --env MLFLOW_EXPERIMENT_NAME=${MLFLOW_EXPERIMENT_NAME} ${DOCKER_IMAGE} \
    python src/dncbfac/api.py "${job_config}"
{% endraw %}